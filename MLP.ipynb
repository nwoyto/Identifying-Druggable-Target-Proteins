{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50, loss 0.3231762945652008\n",
      "epoch 100, loss 0.30172285437583923\n",
      "epoch 150, loss 0.2847646474838257\n",
      "epoch 200, loss 0.26048776507377625\n",
      "epoch 250, loss 0.23872260749340057\n",
      "epoch 300, loss 0.2162296175956726\n",
      "epoch 350, loss 0.19265933334827423\n",
      "epoch 400, loss 0.17052334547042847\n",
      "epoch 450, loss 0.1609843224287033\n",
      "epoch 500, loss 0.13900142908096313\n",
      "epoch 550, loss 0.1274380385875702\n",
      "epoch 600, loss 0.1247907355427742\n",
      "epoch 650, loss 0.10765570402145386\n",
      "epoch 700, loss 0.0998276025056839\n",
      "epoch 750, loss 0.09689208120107651\n",
      "epoch 800, loss 0.09705770015716553\n",
      "epoch 850, loss 0.08662553876638412\n",
      "epoch 900, loss 0.07990854978561401\n",
      "epoch 950, loss 0.08035493642091751\n",
      "epoch 1000, loss 0.07886695116758347\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('DataFiles/ImportantFeatures.csv')\n",
    "df.head()\n",
    "\n",
    "# Define the model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.layer4 = nn.Linear(hidden_size3, hidden_size4)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.output_layer = nn.Linear(hidden_size4, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Split the data into train and test sets\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the input size, hidden sizes, and output size\n",
    "input_size = 59\n",
    "hidden_size1 = 128\n",
    "hidden_size2 = 64\n",
    "hidden_size3 = 32\n",
    "hidden_size4 = 16\n",
    "output_size = 2\n",
    "\n",
    "# Convert dataframe to tensor\n",
    "X_train = torch.Tensor(df_train.iloc[:, 1:].values)\n",
    "y_train = torch.Tensor(df_train.iloc[:, 0].values)\n",
    "X_test = torch.Tensor(df_test.iloc[:, 1:].values)\n",
    "y_test = torch.Tensor(df_test.iloc[:, 0].values)\n",
    "\n",
    "\n",
    "# Initialize the model, criterion, and optimizer\n",
    "model = MLP(input_size, hidden_size1, hidden_size2, hidden_size3, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 1000\n",
    "early_stopping_epochs = 20\n",
    "early_stopping_counter = 0\n",
    "best_loss = float(\"inf\")\n",
    "l1_lambda = 0.0001\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train)\n",
    "    loss = loss_fn(output, y_train.long()) + l1_lambda * torch.norm(model.layer1.weight, 1)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if loss.item() < best_loss:\n",
    "        best_loss = loss.item()\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "\n",
    "    if early_stopping_counter == early_stopping_epochs:\n",
    "        break\n",
    "\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(f'epoch {epoch+1}, loss {loss.item()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize lists to store the training and test losses\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train)\n",
    "    train_loss = criterion(output, y_train.long())\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Compute the test loss\n",
    "    with torch.no_grad():\n",
    "        test_output = model(X_test)\n",
    "        test_loss = criterion(test_output, y_test.long())\n",
    "    \n",
    "    # Append the training and test losses to the corresponding lists\n",
    "    train_losses.append(train_loss.item())\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('Epoch [{}/{}], Train Loss: {:.4f}, Test Loss: {:.4f}'.format(epoch + 1, num_epochs, train_loss.item(), test_loss.item()))\n",
    "\n",
    "# Plot the training and test losses\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 65\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39mfor\u001b[39;00m param \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mparameters():\n\u001b[1;32m     64\u001b[0m     reg_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msum(torch\u001b[39m.\u001b[39mabs(param))\n\u001b[0;32m---> 65\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, y_train\u001b[39m.\u001b[39mlong()) \u001b[39m+\u001b[39m l1_lambda \u001b[39m*\u001b[39m reg_loss\n\u001b[1;32m     67\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m     68\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m1000\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('DataFiles/ImportantFeatures.csv')\n",
    "df.head()\n",
    "\n",
    "# Define the model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(hidden_size1, hidden_size2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.layer3 = nn.Linear(hidden_size2, hidden_size3)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.layer4 = nn.Linear(hidden_size3, hidden_size4)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.output_layer = nn.Linear(hidden_size4, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Split the data into train and test sets\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the input size, hidden sizes, and output size\n",
    "input_size = 59\n",
    "hidden_size1 = 128\n",
    "hidden_size2 = 64\n",
    "hidden_size3 = 32\n",
    "hidden_size4 = 16\n",
    "output_size = 2\n",
    "\n",
    "# Convert dataframe to tensor\n",
    "X_train = torch.Tensor(df_train.iloc[:, 1:].values)\n",
    "y_train = torch.Tensor(df_train.iloc[:, 0].values)\n",
    "X_test = torch.Tensor(df_test.iloc[:, 1:].values)\n",
    "y_test = torch.Tensor(df_test.iloc[:, 0].values)\n",
    "\n",
    "\n",
    "# Initialize the model, criterion, and optimizer\n",
    "model = MLP(input_size, hidden_size1, hidden_size2, hidden_size3, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Add L1 regularization to the model\n",
    "l1_lambda = 0.0001\n",
    "reg_loss = 0\n",
    "for param in model.parameters():\n",
    "    reg_loss += torch.sum(torch.abs(param))\n",
    "loss = criterion(output, y_train.long()) + l1_lambda * reg_loss\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 1000\n",
    "early_stopping_epochs = 20\n",
    "early_stopping_counter = 0\n",
    "best_loss = float(\"inf\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train)\n",
    "    loss = criterion(output, y_train.long())\n",
    "    loss += sum(abs(param) for param in model.parameters())*1e-5 # Incorporating L1 regularization\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Early stopping\n",
    "    if loss.item() < best_loss:\n",
    "        best_loss = loss.item()\n",
    "        early_stopping_counter = 0\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "    \n",
    "    if early_stopping_counter >= early_stopping_epochs:\n",
    "        print(\"Early stopping at epoch {}\".format(epoch))\n",
    "        break\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, loss.item()))\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the model\n",
    "# with torch.no_grad():\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "#     output = model(X_test)\n",
    "#     _, predicted = torch.max(output.data, 1)\n",
    "#     total += y_test.size(0)\n",
    "#     correct += (predicted == y_test).sum().item()\n",
    "#     print('Accuracy of the network on the test data: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize lists to store training and test losses\n",
    "# train_losses = []\n",
    "# test_losses = []\n",
    "\n",
    "# # Train the model\n",
    "# num_epochs = 300\n",
    "# for epoch in range(num_epochs):\n",
    "#     optimizer.zero_grad()\n",
    "#     output = model(X_train)\n",
    "#     train_loss = criterion(output, y_train.long())\n",
    "#     train_loss.backward()\n",
    "#     optimizer.step()\n",
    "#     train_losses.append(train_loss.item())\n",
    "    \n",
    "#     if (epoch + 1) % 10 == 0:\n",
    "#         print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch + 1, num_epochs, train_loss.item()))\n",
    "        \n",
    "#         # Compute test loss\n",
    "#         test_output = model(X_test)\n",
    "#         test_loss = criterion(test_output, y_test.long())\n",
    "#         test_losses.append(test_loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize lists to store the training and test losses\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X_train)\n",
    "    train_loss = criterion(output, y_train.long())\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Compute the test loss\n",
    "    with torch.no_grad():\n",
    "        test_output = model(X_test)\n",
    "        test_loss = criterion(test_output, y_test.long())\n",
    "    \n",
    "    # Append the training and test losses to the corresponding lists\n",
    "    train_losses.append(train_loss.item())\n",
    "    test_losses.append(test_loss.item())\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('Epoch [{}/{}], Train Loss: {:.4f}, Test Loss: {:.4f}'.format(epoch + 1, num_epochs, train_loss.item(), test_loss.item()))\n",
    "\n",
    "# Plot the training and test losses\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    output = model(X_test)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    total += y_test.size(0)\n",
    "    correct += (predicted == y_test).sum().item()\n",
    "    predictions = predicted\n",
    "    print('Accuracy of the network on the test data: {} %'.format(100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Torch_SB2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2280b3b0838f6b356f0353db82bec828a8190df71aafda87a9fec5c542161bb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
